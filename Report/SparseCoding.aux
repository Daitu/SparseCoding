\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\zref@newlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand*\HyPL@Entry[1]{}
\HyPL@Entry{0<</S/D>>}
\providecommand\tcolorbox@label[2]{}
\HyPL@Entry{1<</S/D>>}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{4}{chapter.1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:Introduction}{{1}{4}{Introduction}{chapter.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Hosting Laboratory}{4}{section.1.1}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Context}{4}{section.1.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Basic pipeline of speech recognition\relax }}{5}{figure.caption.3}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig: Speech Procesing expain}{{1.1}{5}{Basic pipeline of speech recognition\relax }{figure.caption.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Organization}{5}{section.1.3}}
\citation{8398588}
\citation{258082}
\citation{305222}
\citation{Olshausen97sparsecoding}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Traditional Sparse Coding}{6}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:SparseCoding}{{2}{6}{Traditional Sparse Coding}{chapter.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}\textit  {Sparseland}}{6}{section.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}The idea behind \textit  {Sparseland}}{6}{subsection.2.1.1}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Mathematical formulation}{6}{section.2.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Example of Sparse Coding reconstruction\relax }}{7}{figure.caption.4}}
\newlabel{fig:exemple}{{2.1}{7}{Example of Sparse Coding reconstruction\relax }{figure.caption.4}{}}
\citation{258082}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Learning step}{8}{section.2.3}}
\newlabel{algo:algo1}{{\caption@xref {algo:algo1}{ on input line 62}}{8}{Learning step}{section.2.3}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Learning step\relax }}{8}{algorithm.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Inference of Sparse code}{8}{subsection.2.3.1}}
\@writefile{toc}{\contentsline {subsubsection}{$l_0$ norm based}{8}{section*.5}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces Orthogonal Matching Pursuit Algorithm\relax }}{8}{algorithm.2}}
\@writefile{toc}{\contentsline {subsubsection}{$l_1$ norm based}{8}{section*.6}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {3}{\ignorespaces ISTA (Iterative Shrinkage and Thresholding Algorithm)\relax }}{9}{algorithm.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Inference of Dictionary}{9}{subsection.2.3.2}}
\@writefile{toc}{\contentsline {subsubsection}{Algorithm 1: Gradient Descent }{9}{section*.7}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Example of gradient descent\relax }}{9}{figure.caption.8}}
\newlabel{fig:gradientDescent}{{2.2}{9}{Example of gradient descent\relax }{figure.caption.8}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {4}{\ignorespaces Dictionary Learning: Gradient descent\relax }}{10}{algorithm.4}}
\@writefile{toc}{\contentsline {subsubsection}{Algorithm 2: Block-coordinate descent}{10}{section*.9}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Example of Block-Coordinate descent\relax }}{10}{figure.caption.10}}
\newlabel{fig:BlockCoordDescent}{{2.3}{10}{Example of Block-Coordinate descent\relax }{figure.caption.10}{}}
\citation{Mairal:2009:ODL:1553374.1553463}
\@writefile{loa}{\contentsline {algorithm}{\numberline {5}{\ignorespaces Dictionary Learning: Block-coordinate descent\relax }}{11}{algorithm.5}}
\@writefile{toc}{\contentsline {subsubsection}{Algorithm 3: Online learning algorithm}{11}{section*.11}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {6}{\ignorespaces Dictionary Learning: Online learning algorithm\relax }}{11}{algorithm.6}}
\@writefile{toc}{\contentsline {paragraph}{Optimizing the Algorithm}{11}{section*.12}}
\citation{1710377}
\@writefile{toc}{\contentsline {subsubsection}{Algorithm 4: K-SVD}{12}{section*.13}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {7}{\ignorespaces K-SVD algorithm\relax }}{12}{algorithm.7}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Dataset and Toolbox}{13}{section.2.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.1}MNIST}{13}{subsection.2.4.1}}
\pgfsyspdfmark {pgfid1}{4736286}{36114415}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Example of MNIST's handwritten digits\relax }}{13}{figure.caption.14}}
\newlabel{fig:MNIST}{{2.4}{13}{Example of MNIST's handwritten digits\relax }{figure.caption.14}{}}
\@writefile{toc}{\contentsline {subsubsection}{SPAMS}{13}{section*.15}}
\citation{Mairal:2009:ODL:1553374.1553463}
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Experimentation details}{14}{section.2.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.1}Application of traditional Coding on MNIST}{14}{subsection.2.5.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Cost's evolution depends on the number of atoms in the dictionary\relax }}{14}{figure.caption.16}}
\newlabel{fig:CostEvolution}{{2.5}{14}{Cost's evolution depends on the number of atoms in the dictionary\relax }{figure.caption.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces Some of the 1400 atoms in the dictionary\relax }}{14}{figure.caption.17}}
\newlabel{fig:D_1400k}{{2.6}{14}{Some of the 1400 atoms in the dictionary\relax }{figure.caption.17}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces Reconstruction using $D \gamma $ and $\gamma $\relax }}{15}{figure.caption.18}}
\newlabel{fig:Recons}{{2.7}{15}{Reconstruction using $D \gamma $ and $\gamma $\relax }{figure.caption.18}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.2}Classification for traditional Sparse Coding}{15}{subsection.2.5.2}}
\citation{8294264}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Discriminative Sparse Coding }{16}{chapter.3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:Discriminative}{{3}{16}{Discriminative Sparse Coding}{chapter.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Objective of discriminative Sparse Coding\relax }}{16}{figure.caption.19}}
\newlabel{fig:discriminative}{{3.1}{16}{Objective of discriminative Sparse Coding\relax }{figure.caption.19}{}}
\citation{5539964}
\citation{6516503}
\citation{6516503}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}One dictionary per class}{17}{section.3.1}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Label Consistent K-SVD}{17}{section.3.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Idea}{17}{subsection.3.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}LC-KSVD1}{17}{subsection.3.2.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Example of Q, each color corresponding to a class (white color is the lack of classes). Signal 1,3 and 6 are from class 1; signal 2 and 5 from class 2 and signal 5 from class 3\relax }}{18}{figure.caption.20}}
\newlabel{fig:Q}{{3.2}{18}{Example of Q, each color corresponding to a class (white color is the lack of classes). Signal 1,3 and 6 are from class 1; signal 2 and 5 from class 2 and signal 5 from class 3\relax }{figure.caption.20}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {8}{\ignorespaces Label Consistent K-SVD 1 (LC-KSVD1)\relax }}{18}{algorithm.8}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Experiment details}{19}{section.3.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}Application of Label-Consistent K-SVD on MNIST}{19}{subsection.3.3.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Some example of atoms from the dictionary\relax }}{19}{figure.caption.21}}
\newlabel{fig:DLCKSVD}{{3.3}{19}{Some example of atoms from the dictionary\relax }{figure.caption.21}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Examples of LC-KVD on MNIST data\relax }}{19}{figure.caption.22}}
\newlabel{fig:MNIST_LC}{{3.4}{19}{Examples of LC-KVD on MNIST data\relax }{figure.caption.22}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}Classification for Label-Consistent K-SVD}{20}{subsection.3.3.2}}
\citation{Zheng:2016:ESD:2939672.2939824}
\citation{6618901}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Convolutional Sparse Coding}{21}{chapter.4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:Conv}{{4}{21}{Convolutional Sparse Coding}{chapter.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Idea}{21}{section.4.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Idea behind Convolutional Sparse Coding\relax }}{21}{figure.caption.23}}
\newlabel{fig:csc_idea}{{4.1}{21}{Idea behind Convolutional Sparse Coding\relax }{figure.caption.23}{}}
\citation{6618901}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}Problem formulation}{22}{subsection.4.1.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces CSC principle by Michael Elad \footnotemark \relax }}{22}{figure.caption.24}}
\newlabel{fig:CSC_slide}{{4.2}{22}{CSC principle by Michael Elad \protect \footnotemark \relax }{figure.caption.24}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Example of reconstruction using atoms $d_j$ and features map $z_j$\footnotemark \relax }}{22}{figure.caption.25}}
\newlabel{fig:CSC_test}{{4.3}{22}{Example of reconstruction using atoms $d_j$ and features map $z_j$\protect \footnotemark \relax }{figure.caption.25}{}}
\citation{6618901}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Inference of CSC}{23}{section.4.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}Augmented Lagrangian}{23}{subsection.4.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}Quad-decomposition of the objective}{23}{subsection.4.2.2}}
\@writefile{toc}{\contentsline {subsubsection}{Subproblem z}{23}{section*.26}}
\@writefile{toc}{\contentsline {subsubsection}{Subproblem t}{23}{section*.27}}
\citation{wohlberg-2017-sporco}
\citation{wohlberg-2016-sporco}
\@writefile{toc}{\contentsline {subsubsection}{Subproblem d}{24}{section*.28}}
\@writefile{toc}{\contentsline {subsubsection}{Subproblem s}{24}{section*.29}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.3}Lagrange Multiplier Update}{24}{subsection.4.2.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.4}Penalty update}{24}{subsection.4.2.4}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}SPORCO}{24}{section.4.3}}
\citation{best-practices-for-convolutional-neural-networks-applied-to-visual-document-analysis}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Experimentation details}{26}{section.4.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.1}Application of Convolutional Sparse Coding on MNIST}{26}{subsection.4.4.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces Filters from the convolutional dictionary\relax }}{26}{figure.caption.30}}
\newlabel{fig:CSC_D}{{4.4}{26}{Filters from the convolutional dictionary\relax }{figure.caption.30}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces Examples of reconstruction using CSC\relax }}{26}{figure.caption.31}}
\newlabel{fig:CSC_recons}{{4.5}{26}{Examples of reconstruction using CSC\relax }{figure.caption.31}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces Activation maps for a handwritten "7"\relax }}{27}{figure.caption.32}}
\newlabel{fig:activationMaps}{{4.6}{27}{Activation maps for a handwritten "7"\relax }{figure.caption.32}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces Example of shift-invariance power in a characteristic features map ($5^{th}$ atom in the CSC dictionary)\relax }}{27}{figure.caption.33}}
\newlabel{fig:CSCproof}{{4.7}{27}{Example of shift-invariance power in a characteristic features map ($5^{th}$ atom in the CSC dictionary)\relax }{figure.caption.33}{}}
\citation{DBLP:journals/corr/abs-1708-08705}
\citation{8398588}
\citation{DBLP:journals/corr/abs-1708-08705}
\citation{8398588}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Discriminative Convolutional Sparse Coding}{28}{chapter.5}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:SupervisedConv}{{5}{28}{Discriminative Convolutional Sparse Coding}{chapter.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}ML-CSC}{28}{section.5.1}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {9}{\ignorespaces Multi-Layer Convolutional Dictionary Learning\relax }}{28}{algorithm.9}}
\citation{DBLP:journals/corr/abs-1708-08705}
\citation{DBLP:journals/corr/abs-1708-08705}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Tests details}{29}{section.5.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.1}Application of ML-CSC on MNIST}{29}{subsection.5.2.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces Dictionary's atoms at each layer\relax }}{29}{figure.caption.34}}
\newlabel{fig:DCSC}{{5.1}{29}{Dictionary's atoms at each layer\relax }{figure.caption.34}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces From atoms to molecules: Illustration of the ML-CSC model for a number 6. Two local convolutional atoms (bottom row) are combined to create slightly more complex structures – molecules – at the second level, which are then combined to create the global atom representing, in this case, a digit \cite  {DBLP:journals/corr/abs-1708-08705}\relax }}{29}{figure.caption.35}}
\newlabel{fig:decomp}{{5.2}{29}{From atoms to molecules: Illustration of the ML-CSC model for a number 6. Two local convolutional atoms (bottom row) are combined to create slightly more complex structures – molecules – at the second level, which are then combined to create the global atom representing, in this case, a digit \cite {DBLP:journals/corr/abs-1708-08705}\relax }{figure.caption.35}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.2}Classification for ML-CSC}{29}{subsection.5.2.2}}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}LC-ML-CSC}{30}{section.5.3}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {10}{\ignorespaces Labels Consistent Multi Layers Convolutional Sparse Coding (LC-MLCSC )\relax }}{30}{algorithm.10}}
\citation{Rumelhart:1986:LIR:104279.104293}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Auto-encoders}{31}{chapter.6}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:AE}{{6}{31}{Auto-encoders}{chapter.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Principle}{31}{section.6.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.1}{\ignorespaces Basic architecture of AutoEncoder\relax }}{31}{figure.caption.36}}
\newlabel{fig:AE}{{6.1}{31}{Basic architecture of AutoEncoder\relax }{figure.caption.36}{}}
\citation{DBLP:journals/corr/MakhzaniF13}
\@writefile{toc}{\contentsline {section}{\numberline {6.2}Sparse AutoEncoder}{32}{section.6.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.2}{\ignorespaces Example of Sparse AutoEncoder architecture\relax }}{32}{figure.caption.37}}
\newlabel{fig:SAE}{{6.2}{32}{Example of Sparse AutoEncoder architecture\relax }{figure.caption.37}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.3}Labels Consistent AutoEncoder}{33}{section.6.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.3}{\ignorespaces Example of Label Consistant Autoencoder architecture\relax }}{33}{figure.caption.38}}
\newlabel{fig:LC_AE}{{6.3}{33}{Example of Label Consistant Autoencoder architecture\relax }{figure.caption.38}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.4}Experimentation details}{34}{section.6.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4.1}Application of different Autoencoder on MNIST}{34}{subsection.6.4.1}}
\@writefile{toc}{\contentsline {subsubsection}{K Sparse Autoencoder}{34}{section*.39}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.4}{\ignorespaces Reconstruction using decoder and encoded data\relax }}{34}{figure.caption.40}}
\newlabel{fig:SAE_result}{{6.4}{34}{Reconstruction using decoder and encoded data\relax }{figure.caption.40}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.5}{\ignorespaces K Sparse Autoencoder using convolution, pooling, upsampling results\relax }}{34}{figure.caption.41}}
\newlabel{fig:SAEconv}{{6.5}{34}{K Sparse Autoencoder using convolution, pooling, upsampling results\relax }{figure.caption.41}{}}
\@writefile{toc}{\contentsline {subsubsection}{Labels Consistent Autoencoder}{34}{section*.42}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.6}{\ignorespaces MNIST samples with the LC-Autoencoder\relax }}{34}{figure.caption.43}}
\newlabel{fig:LCAE}{{6.6}{34}{MNIST samples with the LC-Autoencoder\relax }{figure.caption.43}{}}
\@writefile{toc}{\contentsline {subsubsection}{Label Consistent Sparse Autoencoder}{34}{section*.44}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.7}{\ignorespaces MNIST samples with the Sparse LC-Autoencoder\relax }}{35}{figure.caption.45}}
\newlabel{fig:SLCAE}{{6.7}{35}{MNIST samples with the Sparse LC-Autoencoder\relax }{figure.caption.45}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4.2}Classification for Autoencoder}{35}{subsection.6.4.2}}
\bibstyle{plain}
\bibdata{efficient-sparse-coding-algorithms.bib}
\@writefile{toc}{\contentsline {chapter}{\numberline {7}Conclusion}{36}{chapter.7}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:Conclusion}{{7}{36}{Conclusion}{chapter.7}{}}
\bibcite{1710377}{1}
\bibcite{6618901}{2}
\bibcite{305222}{3}
\bibcite{6516503}{4}
\bibcite{Mairal:2009:ODL:1553374.1553463}{5}
\bibcite{DBLP:journals/corr/MakhzaniF13}{6}
\bibcite{258082}{7}
\bibcite{Olshausen97sparsecoding}{8}
\bibcite{8398588}{9}
\bibcite{5539964}{10}
\bibcite{Rumelhart:1986:LIR:104279.104293}{11}
\bibcite{best-practices-for-convolutional-neural-networks-applied-to-visual-document-analysis}{12}
\bibcite{DBLP:journals/corr/abs-1708-08705}{13}
\bibcite{wohlberg-2016-sporco}{14}
\bibcite{wohlberg-2017-sporco}{15}
\bibcite{8294264}{16}
\bibcite{Zheng:2016:ESD:2939672.2939824}{17}
